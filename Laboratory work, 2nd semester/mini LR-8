import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from sklearn.kernel_ridge import KernelRidge
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
import random

# Генерация данных
def f(x):
    return np.sin(x) + 0.5 * x

np.random.seed(42)
x = np.linspace(0, 10, 100)
y = f(x) + np.random.uniform(-0.5, 0.5, 100)

# Преобразование x для sklearn (требуется двумерный массив)
x_sklearn = x.reshape(-1, 1)

# Метод 1: Kernel Ridge Regression
kr = KernelRidge(alpha=1.0, kernel='rbf', gamma=0.1)
kr.fit(x_sklearn, y)
y_kr = kr.predict(x_sklearn)
mse_kr = mean_squared_error(y, y_kr)

# Метод 2: Support Vector Regression
svr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)
svr.fit(x_sklearn, y)
y_svr = svr.predict(x_sklearn)
mse_svr = mean_squared_error(y, y_svr)

# Метод 3: Random Forest Regressor
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(x_sklearn, y)
y_rf = rf.predict(x_sklearn)
mse_rf = mean_squared_error(y, y_rf)

# Построение графиков
plt.figure(figsize=(15, 5))

# График 1: Kernel Ridge
plt.subplot(1, 3, 1)
plt.scatter(x, y, color='blue', label='Исходные точки')
plt.plot(x, f(x), color='green', label='Исходная функция')
plt.plot(x, y_kr, color='red', label='Kernel Ridge')
plt.title(f'Kernel Ridge (MSE: {mse_kr:.4f})')
plt.legend()

# График 2: SVR
plt.subplot(1, 3, 2)
plt.scatter(x, y, color='blue', label='Исходные точки')
plt.plot(x, f(x), color='green', label='Исходная функция')
plt.plot(x, y_svr, color='red', label='SVR')
plt.title(f'SVR (MSE: {mse_svr:.4f})')
plt.legend()

# График 3: Random Forest
plt.subplot(1, 3, 3)
plt.scatter(x, y, color='blue', label='Исходные точки')
plt.plot(x, f(x), color='green', label='Исходная функция')
plt.plot(x, y_rf, color='red', label='Random Forest')
plt.title(f'Random Forest (MSE: {mse_rf:.4f})')
plt.legend()

plt.tight_layout()
plt.show()
